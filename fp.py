# -*- coding: utf-8 -*-
"""FP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17sQJL_dZMhgZ9e-haXwuwPFsdSoACwd2

# **Overview**

## **Deskripsi Dataset SiPongi-BMKG Sumatera**

Dataset ini merupakan gabungan data dari SiPongi (Sistem Pemantauan Kebakaran) dan BMKG (Badan Meteorologi, Klimatologi, dan Geofisika) untuk wilayah Sumatera tahun 2025. Dataset ini digunakan untuk analisis machine learning terkait dengan insiden kebakaran.

### Kolom Geografis dan Temporal:
- **Provinsi**: Nama provinsi lokasi kejadian
- **Kab Kota**: Nama kabupaten/kota lokasi kejadian
- **Kecamatan**: Nama kecamatan lokasi kejadian
- **Desa**: Nama desa lokasi kejadian
- **Tanggal**: Tanggal kejadian dalam format YYYY-MM-DD
- **Waktu**: Waktu kejadian dalam format HH:MM WIB
- **Latitude**: Koordinat lintang lokasi kejadian
- **Longitude**: Koordinat bujur lokasi kejadian

### Kolom Deteksi:
- **Satelit**: Satelit yang mendeteksi kejadian (contoh: NASA-SNPP, NASA-NOAA20)
- **Confidence**: Tingkat keyakinan deteksi (contoh: Medium)

### Kolom Parameter Meteorologis:
- **TN**: Temperatur minimum dalam derajat Celsius
- **TX**: Temperatur maksimum dalam derajat Celsius
- **TAVG**: Temperatur rata-rata dalam derajat Celsius
- **RH_AVG**: Kelembapan rata-rata dalam persentase
- **RR**: Curah hujan dalam milimeter
- **SS**: Lamanya penyinaran matahari dalam jam
- **FF_X**: Kecepatan angin maksimum dalam knot
- **DDD_X**: Arah angin saat kecepatan maksimum dalam derajat
- **FF_AVG**: Kecepatan angin rata-rata dalam knot
- **DDD_CAR**: Arah angin terbanyak/dominan (contoh: N untuk utara)

## **Analisis yang Dilakukan**
1. **Cloning dan Instalasi Library**: Menyiapkan lingkungan dengan mengklon repositori GitHub dataset dan menginstal library untuk pemilihan fitur dan pemodelan.

2. **Pemilihan Fitur (Feature Selection)**: Mengidentifikasi fitur yang paling relevan menggunakan tiga metode berbeda:
   - **Information Gain**: Mengukur informasi yang diberikan fitur tentang variabel target
   - **Chi-Squared Test**: Mengevaluasi ketergantungan antara fitur kategorikal dan target
   - **Fisher's Score**: Memilih fitur yang terbaik dalam memisahkan kelas-kelas target

3. **Penanganan Nilai yang Hilang**: Memeriksa dan melaporkan rasio nilai hilang, menyoroti fitur dengan lebih dari 30% data hilang.

4. **Pemodelan**: Membangun dan mengevaluasi tiga model klasifikasi untuk memprediksi variabel target 'DDD_CAR':
   - **Random Forest**: Metode ensemble yang menggunakan beberapa pohon keputusan
   - **Decision Tree**: Model berbasis pohon keputusan tunggal
   - **XGBoost**: Metode gradient boosting yang menggunakan pohon keputusan

5. **Perbandingan Kinerja Model**: Membandingkan kinerja ketiga model menggunakan metrik akurasi, presisi, recall, dan F1-score, serta memvisualisasikan hasilnya dalam bentuk tabel dan grafik.

Dataset ini membantu menganalisis hubungan antara kondisi meteorologis dan kejadian kebakaran, serta membangun model prediktif untuk mengidentifikasi area berisiko tinggi berdasarkan parameter meteorologi.

# **1. Persiapan Dataset**
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install skfeature-chappers

!git clone https://github.com/azharpratama/sipongi-bmkg-sumatera-dataset-2025.git -q
dataset = 'sipongi-bmkg-sumatera-dataset-2025/final.csv'

"""

*   **Cloning**: Perintah ini digunakan untuk menyalin repositori dataset yang berisi file .csv ke dalam lingkungan lokal. Hal ini memungkinkan kita untuk bekerja dengan dataset yang relevan.



"""

import pandas as pd
df = pd.read_csv(dataset)
df.head(10)

"""

1.  **Memuat dataset**: pd.read_csv digunakan untuk memuat dataset .csv ke dalam bentuk DataFrame menggunakan pandas.

2. **Melihat data**: .head(10) menampilkan 10 baris pertama dari dataset untuk memberi gambaran umum mengenai isinya.

"""

summary = df.describe()
summary

"""

*   **Deskripsi data**: df.describe() memberikan ringkasan statistik dari dataset, termasuk nilai rata-rata, deviasi standar, nilai minimum dan maksimum, serta persentil data untuk setiap kolom numerik.
"""

jumlah_data = len(df)
print("Jumlah data (baris):", jumlah_data)

print("Jumlah kolom:", df.shape[1])

"""*   **Jumlah data**: len(df) memberikan jumlah baris dalam dataset.

*   **Jumlah kolom**: df.shape[1] memberikan jumlah kolom dalam dataset.

## **Penanganan Missing Values**
"""

#Missing Values

import pandas as pd
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv(dataset)

# Calculate missing value ratio for each feature
missing_ratio = df.isnull().sum() / len(df)

# Sort features by missing ratio
missing_ratio_sorted = missing_ratio.sort_values(ascending=True)

# Filter features with missing values
missing_features = missing_ratio_sorted[missing_ratio_sorted > 30]

print("Missing Value Ratio per Feature:\n")
print(missing_features)

if not missing_features.empty:
    plt.figure(figsize=(10, 6))
    missing_features.plot(kind='barh', color='coral')
    plt.title("Missing Value Ratio by Feature")
    plt.xlabel("Ratio")
    plt.ylabel("Features")
    plt.tight_layout()
    plt.show()
else:
    print("No missing values detected.")

"""# **2. Feature Selection**

## **Information Gain**
  Memilih fitur yang memiliki informasi terbesar terkait dengan variabel target (dalam hal ini, DDD_CAR).


*   **mutual_info_classif**: Menghitung Information Gain (IG) untuk setiap fitur. Fitur dengan nilai IG yang lebih tinggi memberikan informasi lebih besar tentang target dan seharusnya lebih relevan.

*  **LabelEncoder**: Digunakan untuk mengonversi variabel kategorikal menjadi format numerik.

*   **Sorting**: Fitur diurutkan berdasarkan skor IG dalam urutan menurun.

*   **Bar chart horizontal**: Digunakan untuk memvisualisasikan skor feature importance berdasarkan Information Gain.
"""

#Feature Importance

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_selection import mutual_info_classif
from sklearn.preprocessing import LabelEncoder

# Load your dataset
df = pd.read_csv(dataset)

# Define the target variable
target_column = 'DDD_CAR'

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Split into features and target
X = df.drop(columns=[target_column])
y = df[target_column]

# Apply Information Gain
ig = mutual_info_classif(X, y, discrete_features='auto', random_state=42)

# Create a dictionary of feature importance scores
feature_scores = {}
for i in range(len(X.columns)):
    feature_scores[X.columns[i]] = ig[i]

# Sort the features by importance score in descending order
sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)

# Print the feature importance scores and the sorted features
for feature, score in sorted_features:
    print("Feature:", feature, "Score:", score)

# Plot a horizontal bar chart of the feature importance scores
fig, ax = plt.subplots(figsize=(10, 6))
y_pos = np.arange(len(sorted_features))
ax.barh(y_pos, [score for feature, score in sorted_features], align="center")
ax.set_yticks(y_pos)
ax.set_yticklabels([feature for feature, score in sorted_features])
ax.invert_yaxis()
ax.set_xlabel("Importance Score")
ax.set_title("Feature Importance Scores (Information Gain)")

# Add importance scores as labels on the horizontal bar chart
for i, v in enumerate([score for feature, score in sorted_features]):
    ax.text(v + 0.01, i, str(round(v, 3)), color="black", fontweight="bold")

plt.tight_layout()
plt.show()

sorted_features_ig = sorted_features

"""## **Chi-Squared Test**
  Menggunakan Chi-Squared Test untuk mengukur hubungan antara fitur dan target, yang umumnya digunakan untuk fitur kategorikal.


*   **Chi-Squared Test**: Mengukur seberapa besar ketergantungan antara fitur dan target. Ini berguna untuk fitur kategorikal.

*  **MinMaxScaler**: Digunakan untuk menyusun fitur dalam rentang antara 0 dan 1 sebelum melakukan Chi-Squared Test.


"""

# Chi-Squared

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_selection import chi2
from sklearn.preprocessing import LabelEncoder, MinMaxScaler

# Load dataset
df = pd.read_csv(dataset)

# Define the target
target_column = 'DDD_CAR'

# Label encoding for categorical columns
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Separate features and target
X = df.drop(columns=[target_column])
y = df[target_column]

# Scale features to [0, 1] range for chi-squared test
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Apply Chi-Squared test
chi_scores, p_values = chi2(X_scaled, y)

# Store results
feature_scores = {X.columns[i]: chi_scores[i] for i in range(len(X.columns))}
sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)

# Print the ranked features
print("Chi-Squared Feature Importance Scores:")
for feature, score in sorted_features:
    print(f"Feature: {feature}, Score: {score:.2f}")

# Visualization
fig, ax = plt.subplots(figsize=(10, 6))
y_pos = np.arange(len(sorted_features))
scores = [score for _, score in sorted_features]
features = [feature for feature, _ in sorted_features]

ax.barh(y_pos, scores, align="center", color="skyblue")
ax.set_yticks(y_pos)
ax.set_yticklabels(features)
ax.invert_yaxis()
ax.set_xlabel("Chi-Squared Score")
ax.set_title("Chi-Squared Feature Importance")

# Add score labels
for i, v in enumerate(scores):
    ax.text(v + 0.5, i, str(round(v, 2)), color="black", fontweight="bold")

plt.tight_layout()
plt.show()

sorted_features_chi2 = sorted_features

"""## **Fisher’s Score**
  Menggunakan Fisher's Score untuk memilih fitur yang paling baik dalam membedakan kelas-kelas target.


*   **Fisher's Score**: Memilih fitur yang dapat dengan baik memisahkan kelas-kelas target.

"""

#Fisher's scores

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from skfeature.function.similarity_based import fisher_score

# Load dataset
df = pd.read_csv(dataset)

# Define the target column
target_column = 'DDD_CAR'

# Encode categorical variables
label_encoders = {}
for col in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

# Define features and target
X = df.drop(columns=[target_column])
Y = df[target_column]

# Calculating Fisher's scores
ranks = fisher_score.fisher_score(X.values, Y.values)

# Plotting the ranks
feat_importances = pd.Series(ranks, index=X.columns).sort_values(ascending=True)
plt.figure(figsize=(10, 6))
feat_importances.plot(kind='barh', color='teal')
plt.title("Fisher’s Score for Feature Selection")
plt.xlabel("Score")
plt.ylabel("Features")
plt.tight_layout()
plt.show()

"""## **Konsolidasi Hasil Feature Selection**

Membuat peringkat konsolidasi dengan menggabungkan hasil dari ketiga metode feature selection (Information Gain, Chi-Squared Test, dan Fisher’s Score). Peringkat rata-rata dihitung untuk setiap fitur, sehingga fitur yang secara konsisten menonjol di berbagai metode akan berada di urutan teratas. Pendekatan ini memberikan gambaran yang lebih komprehensif tentang fitur-fitur paling penting dalam dataset.
"""

# Create a function to normalize scores between 0 and 1 for fair comparison
def normalize_scores(scores):
    min_score = min(scores)
    max_score = max(scores)
    if max_score == min_score:
        return [1.0 for _ in scores]
    return [(s - min_score) / (max_score - min_score) for s in scores]

# Get top features from each method
ig_features = [feature for feature, score in sorted_features_ig]  # Information Gain
chi2_features = [feature for feature, score in sorted_features_chi2]  # Chi-Squared
fisher_features = feat_importances.index.tolist()  # Fisher's Score (reverse order if needed)

# Create a consolidated score dictionary
feature_consolidated = {}
for feature in X.columns:
    # Calculate average rank across methods
    ig_rank = ig_features.index(feature) if feature in ig_features else len(ig_features)
    chi2_rank = chi2_features.index(feature) if feature in chi2_features else len(chi2_features)
    fisher_rank = fisher_features.index(feature) if feature in fisher_features else len(fisher_features)

    avg_rank = (ig_rank + chi2_rank + fisher_rank) / 3.0
    feature_consolidated[feature] = avg_rank

# Sort features by consolidated rank
consolidated_features = sorted(feature_consolidated.items(), key=lambda x: x[1])

# Display top consolidated features
print("Top 10 consolidated features:")
for feature, score in consolidated_features[:10]:
    print(f"Feature: {feature}, Avg Rank: {score:.2f}")

# You already have consolidated features from your three methods
consolidated_features = sorted(feature_consolidated.items(), key=lambda x: x[1])

# Simply select the top 10 features
top_features = [feature for feature, _ in consolidated_features[:10]]

# Final dataset for modeling using top consolidated features
X = df[top_features]
Y = df[target_column]

"""## **Data Balancing**"""

from imblearn.over_sampling import SMOTE

# Pilih top 10 features
top_features = [feature for feature, _ in consolidated_features[:10]]
X = df[top_features]
Y = df[target_column]

# Periksa distribusi kelas
print("Distribusi target sebelum balancing:")
print(pd.Series(Y).value_counts())

# Terapkan SMOTE untuk menyeimbangkan data
smote = SMOTE(random_state=42)
X_balanced, Y_balanced = smote.fit_resample(X, Y)

# Periksa distribusi setelah balancing
print("Distribusi target setelah balancing:")
print(pd.Series(Y_balanced).value_counts())

# Gunakan data yang seimbang untuk modeling
X_old = X
Y_old = Y
X = X_balanced
Y = Y_balanced

# Contoh cara melihat pemetaan original ke encoded values
original_values = label_encoders['DDD_CAR'].inverse_transform([0, 1, 2, 3, 4, 5, 6, 7, 8])
print("Pemetaan nilai numerik ke nilai asli:")
for i, val in enumerate(original_values):
    print(f"{i} -> {val}")

"""# **3. Pemodelan**
Pada tahap pemodelan, dilakukan klasifikasi menggunakan tiga algoritma berbeda: **Random Forest**, **Decision Tree**, dan **XGBoost**. Setiap model dilatih menggunakan data pelatihan dan dievaluasi pada data pengujian untuk memprediksi variabel target `DDD_CAR`. Hasil evaluasi dari ketiga model dibandingkan menggunakan metrik akurasi, presisi, recall, dan F1-score untuk menentukan model dengan performa terbaik pada dataset ini.

## **3.1 Pemodelan dengan Random Forest**

*   **Random Forest** Digunakan untuk membangun model klasifikasi. Menggunakan ensemble method yang melibatkan banyak pohon keputusan untuk meningkatkan akurasi dan mengurangi overfitting.
"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

# Pisahkan data
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Inisialisasi dan latih model Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Prediksi
y_pred = rf_model.predict(X_test)

# Evaluasi model
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

"""## **3.2 Pemodelan Dengan Decision Tree**

*  **Decision Tree** adalah algoritma pembelajaran pohon keputusan yang digunakan untuk pemodelan klasifikasi. Setiap simpul di pohon menggambarkan keputusan atau pertanyaan yang akan membagi data ke dalam kelas yang berbeda.
"""

# Import Libraries
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Decision Tree Model
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
y_dt_pred = dt_model.predict(X_test)

# Evaluation
print("Decision Tree Accuracy:", accuracy_score(y_test, y_dt_pred))
print("Classification Report:\n", classification_report(y_test, y_dt_pred))

"""*   **DecisionTreeClassifier**: Digunakan untuk membangun pohon keputusan dengan menggunakan data pelatihan (X_train dan y_train).

*   **train_test_split**: Membagi data menjadi dua set: satu untuk pelatihan (training) dan satu untuk pengujian (testing).

*   **classification_report**: Memberikan metrik precision, recall, f1-score, dan support untuk masing-masing kelas target, serta rata-rata metrik ini.

## **3.3 Pemodelan Dengan XGBoost**

*  **XGBoost** (Extreme Gradient Boosting) adalah metode ensemble yang menggunakan pohon keputusan dan membangun model yang lebih kuat dengan menggabungkan hasil dari beberapa pohon keputusan.
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from xgboost import XGBClassifier

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Train XGBoost Model
xgb_model = XGBClassifier(eval_metric='mlogloss', random_state=42)
xgb_model.fit(X_train, y_train)

# Predictions
y_pred = xgb_model.predict(X_test)

# Evaluation
print("XGBoost Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

"""*   **XGBClassifier**: Digunakan untuk membangun model XGBoost. Pengaturan use_label_encoder=False menonaktifkan peringatan penggunaan encoder label dan eval_metric='mlogloss' menetapkan metrik evaluasi sebagai log-loss.

*   **train_test_split**: Digunakan untuk membagi dataset menjadi data pelatihan dan data pengujian.

*    **classification_report**: Menyediakan metrik performa yang serupa dengan Decision Tree (precision, recall, f1-score, dan support).

# **4. Perbandingan Kinerja Model**
**Perbandingan Model**: Membuat DataFrame untuk membandingkan hasil evaluasi (akurat, precision, recall, F1) antara model Random Forest, Decision Tree, dan XGBoost.
"""

# Import Libraries
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

# Calculate metrics for Random Forest
y_pred_rf = rf_model.predict(X_test)
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf, recall_rf, f1_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='macro')

# Calculate metrics for Decision Tree
y_pred_dt = dt_model.predict(X_test)
accuracy_dt = accuracy_score(y_test, y_pred_dt)
precision_dt, recall_dt, f1_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='macro')

# Calculate metrics for XGBoost
y_pred_xgb = xgb_model.predict(X_test)
accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
precision_xgb, recall_xgb, f1_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='macro')

# Create DataFrame for comparison
comparison_df = pd.DataFrame({
    "Model": ["Random Forest", "Decision Tree", "XGBoost"],
    "Accuracy": [accuracy_rf, accuracy_dt, accuracy_xgb],
    "Precision (Macro Avg)": [precision_rf, precision_dt, precision_xgb],
    "Recall (Macro Avg)": [recall_rf, recall_dt, recall_xgb],
    "F1-Score (Macro Avg)": [f1_rf, f1_dt, f1_xgb]
})

# Display table
print("Perbandingan Kinerja Model")
display(comparison_df)

# Create visualization
fig, ax = plt.subplots(figsize=(10, 6))
metrics = ["Accuracy", "Precision (Macro Avg)", "Recall (Macro Avg)", "F1-Score (Macro Avg)"]
x = range(len(metrics))

for i, model in enumerate(comparison_df["Model"]):
    values = comparison_df.iloc[i, 1:].values
    ax.plot(x, values, marker='o', label=model)

ax.set_xticks(x)
ax.set_xticklabels(metrics)
ax.set_ylabel("Score")
ax.set_title("Perbandingan Kinerja Model: Random Forest vs Decision Tree vs XGBoost")
ax.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Perbandingan visual**: Grafik garis ini menampilkan metrik yang berbeda untuk ketiga model, memudahkan kita untuk membandingkan performa masing-masing model.

# **5. Evaluasi dengan K-Fold Cross-Validation**
Cross-validation dengan k-fold adalah metode evaluasi yang membagi dataset menjadi k bagian yang sama besar,
kemudian secara bergantian menggunakan k-1 bagian untuk training dan 1 bagian untuk testing.
Proses ini diulang sebanyak k kali dengan fold testing yang berbeda-beda.

Keuntungan metode ini dibanding evaluasi train-test split biasa:
1. Menggunakan seluruh data untuk training maupun testing
2. Hasil evaluasi lebih robust karena dilakukan berkali-kali dengan partisi data yang berbeda
3. Membantu mendeteksi overfitting dengan menunjukkan konsistensi performa model

Berikut hasil evaluasi ketiga model dengan teknik 5-fold cross-validation:

## **Menggunakan Unbalanced Data**
"""

import numpy as np
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

# Define models
models = {
    "Random Forest": rf_model,
    "Decision Tree": dt_model,
    "XGBoost": xgb_model
}

# Number of folds
k_folds = 5

# Dictionary to store results
cv_results = {}

# Perform cross-validation for each model
for name, model in models.items():
    # Get accuracy scores
    accuracy_scores = cross_val_score(model, X_old, Y_old, cv=k_folds, scoring='accuracy')

    # Store results
    cv_results[name] = {
        "Accuracy Scores": accuracy_scores,
        "Mean Accuracy": np.mean(accuracy_scores),
        "Std Dev": np.std(accuracy_scores)
    }

    # Print results
    print(f"\n{name}:")
    print(f"Fold accuracies: {accuracy_scores}")
    print(f"Mean Accuracy: {np.mean(accuracy_scores):.4f} (±{np.std(accuracy_scores):.4f})")

# Create comparison DataFrame
cv_comparison_df = pd.DataFrame({
    "Model": list(models.keys()),
    "Mean CV Accuracy": [cv_results[m]["Mean Accuracy"] for m in models.keys()],
    "Std Dev": [cv_results[m]["Std Dev"] for m in models.keys()],
    "Min Accuracy": [min(cv_results[m]["Accuracy Scores"]) for m in models.keys()],
    "Max Accuracy": [max(cv_results[m]["Accuracy Scores"]) for m in models.keys()]
})

# Display table
print("\nPerbandingan Akurasi dengan Cross-Validation:")
display(cv_comparison_df)

# Compare with single train-test split results
comparison_all = pd.DataFrame({
    "Model": list(models.keys()),
    "Train-Test Split Accuracy": comparison_df["Accuracy"],
    "5-Fold CV Mean Accuracy": [cv_results[m]["Mean Accuracy"] for m in models.keys()]
})

print("\nPerbandingan Akurasi: Train-Test Split vs Cross-Validation:")
display(comparison_all)

# Visualize comparison
plt.figure(figsize=(10, 6))
ind = np.arange(len(models))
width = 0.35

plt.bar(ind - width/2, comparison_all["Train-Test Split Accuracy"], width, label='Train-Test Split')
plt.bar(ind + width/2, comparison_all["5-Fold CV Mean Accuracy"], width, label='5-Fold CV')

plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Perbandingan Akurasi: Train-Test Split vs 5-Fold CV')
plt.xticks(ind, comparison_all["Model"])
plt.legend()
plt.grid(True, axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## **Menggunakan Balanced Data**"""

import numpy as np
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

# Define models
models = {
    "Random Forest": rf_model,
    "Decision Tree": dt_model,
    "XGBoost": xgb_model
}

# Number of folds
k_folds = 5

# Dictionary to store results
cv_results = {}

# Perform cross-validation for each model
for name, model in models.items():
    # Get accuracy scores
    accuracy_scores = cross_val_score(model, X, Y, cv=k_folds, scoring='accuracy')

    # Store results
    cv_results[name] = {
        "Accuracy Scores": accuracy_scores,
        "Mean Accuracy": np.mean(accuracy_scores),
        "Std Dev": np.std(accuracy_scores)
    }

    # Print results
    print(f"\n{name}:")
    print(f"Fold accuracies: {accuracy_scores}")
    print(f"Mean Accuracy: {np.mean(accuracy_scores):.4f} (±{np.std(accuracy_scores):.4f})")

# Create comparison DataFrame
cv_comparison_df = pd.DataFrame({
    "Model": list(models.keys()),
    "Mean CV Accuracy": [cv_results[m]["Mean Accuracy"] for m in models.keys()],
    "Std Dev": [cv_results[m]["Std Dev"] for m in models.keys()],
    "Min Accuracy": [min(cv_results[m]["Accuracy Scores"]) for m in models.keys()],
    "Max Accuracy": [max(cv_results[m]["Accuracy Scores"]) for m in models.keys()]
})

# Display table
print("\nPerbandingan Akurasi dengan Cross-Validation:")
display(cv_comparison_df)

# Compare with single train-test split results
comparison_all = pd.DataFrame({
    "Model": list(models.keys()),
    "Train-Test Split Accuracy": comparison_df["Accuracy"],
    "5-Fold CV Mean Accuracy": [cv_results[m]["Mean Accuracy"] for m in models.keys()]
})

print("\nPerbandingan Akurasi: Train-Test Split vs Cross-Validation:")
display(comparison_all)

# Visualize comparison
plt.figure(figsize=(10, 6))
ind = np.arange(len(models))
width = 0.35

plt.bar(ind - width/2, comparison_all["Train-Test Split Accuracy"], width, label='Train-Test Split')
plt.bar(ind + width/2, comparison_all["5-Fold CV Mean Accuracy"], width, label='5-Fold CV')

plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Perbandingan Akurasi: Train-Test Split vs 5-Fold CV')
plt.xticks(ind, comparison_all["Model"])
plt.legend()
plt.grid(True, axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()